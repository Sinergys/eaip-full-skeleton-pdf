"""
–ú–æ–¥—É–ª—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ OCR –≤ –ø—Ä–æ—Ü–µ—Å—Å –∏–º–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö
–≠–¢–ê–ü 3: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ –ø—Ä–æ—Ü–µ—Å—Å –∏–º–ø–æ—Ä—Ç–∞
"""
import json
import logging
from pathlib import Path
from typing import Dict, Any, Optional, List
from datetime import datetime

from pdf2image import convert_from_path
from PIL import Image

from .gemini_vision_ocr import extract_with_gemini_vision
from .ocr_data_adapter import (
    find_energy_tables_in_ocr,
    identify_resource_type,
    identify_period_type,
    extract_dates_from_table,
    extract_values_from_table,
    convert_to_aggregator_format,
    validate_aggregator_data
)

logger = logging.getLogger(__name__)


def process_pdf_with_ocr(
    pdf_path: str,
    batch_id: str,
    debug_dir: Optional[Path] = None,
    save_debug: bool = True
) -> Optional[Dict[str, Any]]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç PDF —Ñ–∞–π–ª —á–µ—Ä–µ–∑ OCR –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–∞.
    
    –ë–õ–û–ö 3.1: –û–±—Ä–∞–±–æ—Ç–∫–∞ PDF —á–µ—Ä–µ–∑ OCR
    
    Args:
        pdf_path: –ü—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É
        batch_id: ID –∑–∞–≥—Ä—É–∑–∫–∏
        debug_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç–ª–∞–¥–æ—á–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        save_debug: –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ –æ—Ç–ª–∞–¥–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–∞ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    if not Path(pdf_path).exists():
        logger.error(f"PDF —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {pdf_path}")
        return None
    
    try:
        logger.info(f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞ PDF —á–µ—Ä–µ–∑ OCR: {Path(pdf_path).name}")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–ª—è –Ω–∞—á–∞–ª–∞)
        images = convert_from_path(str(pdf_path), dpi=200, first_page=1, last_page=1)
        if not images:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {pdf_path}")
            return None
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        temp_image_path = Path(pdf_path).parent / f"temp_ocr_{batch_id}.png"
        images[0].save(temp_image_path, 'PNG')
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º OCR
        ocr_result = extract_with_gemini_vision(str(temp_image_path), page_num=1, skip_adaptive_retry=False)
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª (—Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏)
        try:
            if temp_image_path.exists():
                # –ü—Ä–æ–±—É–µ–º –∑–∞–∫—Ä—ã—Ç—å —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω –æ—Ç–∫—Ä—ã—Ç
                import time
                time.sleep(0.1)  # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è —Ñ–∞–π–ª–∞
                temp_image_path.unlink()
        except (PermissionError, OSError) as e:
            # –ï—Å–ª–∏ —Ñ–∞–π–ª –∑–∞–Ω—è—Ç, –ø—Ä–æ–±—É–µ–º —É–¥–∞–ª–∏—Ç—å –ø–æ–∑–∂–µ –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {temp_image_path}: {e}. –§–∞–π–ª –±—É–¥–µ—Ç —É–¥–∞–ª—ë–Ω –ø–æ–∑–∂–µ.")
            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤ –æ—á–µ—Ä–µ–¥—å –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –æ—Å—Ç–∞–≤–∏—Ç—å
        
        if not ocr_result or ocr_result.get("error"):
            logger.error(f"–û—à–∏–±–∫–∞ OCR: {ocr_result.get('error', 'unknown')}")
            return None
        
        # –ù–∞—Ö–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—ã —Å –¥–∞–Ω–Ω—ã–º–∏ —ç–Ω–µ—Ä–≥–æ—Ä–µ—Å—É—Ä—Å–æ–≤
        found_tables = find_energy_tables_in_ocr(ocr_result)
        
        if not found_tables:
            logger.warning(f"–¢–∞–±–ª–∏—Ü—ã —Å –¥–∞–Ω–Ω—ã–º–∏ —ç–Ω–µ—Ä–≥–æ—Ä–µ—Å—É—Ä—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {Path(pdf_path).name}")
            return None
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –Ω–∞–π–¥–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
        aggregated_resources = {}
        
        for table_info in found_tables:
            table = table_info["table"]
            resource_type = identify_resource_type(table, table_info.get("resource_type"))
            period_type = identify_period_type(table)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—ã –∏ –∑–Ω–∞—á–µ–Ω–∏—è
            dates_data = extract_dates_from_table(table, period_type)
            values_data = extract_values_from_table(table, resource_type)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–∞
            aggregator_data = convert_to_aggregator_format(
                dates_data, values_data, resource_type, period_type
            )
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
            validation_result = validate_aggregator_data(aggregator_data)
            
            if not validation_result.get("is_valid"):
                logger.warning(
                    f"–î–∞–Ω–Ω—ã–µ –Ω–µ –ø—Ä–æ—à–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–ª—è {resource_type}: "
                    f"{len(validation_result.get('errors', []))} –æ—à–∏–±–æ–∫"
                )
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø–∞–º —Ä–µ—Å—É—Ä—Å–æ–≤
            for res_type, res_data in aggregator_data.items():
                if res_type not in aggregated_resources:
                    aggregated_resources[res_type] = {}
                aggregated_resources[res_type].update(res_data)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–∞
        result = {
            "resources": aggregated_resources,
            "generated_at": datetime.now().isoformat(),
            "source": {
                "type": "ocr",
                "file_path": str(pdf_path),  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º Path –≤ —Å—Ç—Ä–æ–∫—É
                "batch_id": batch_id,
                "confidence": ocr_result.get("confidence", 0.0),
                "tables_count": ocr_result.get("tables_count", 0)
            }
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        if save_debug and debug_dir:
            debug_dir.mkdir(parents=True, exist_ok=True)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã OCR
            ocr_debug_file = debug_dir / f"{batch_id}_ocr_result.json"
            with open(ocr_debug_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "batch_id": batch_id,
                    "pdf_path": pdf_path,
                    "ocr_result": ocr_result,
                    "found_tables": [
                        {
                            "resource_type": t.get("resource_type"),
                            "confidence_score": t.get("confidence_score"),
                            "table_index": t.get("table_index")
                        }
                        for t in found_tables
                    ],
                    "aggregated": result,
                    "timestamp": datetime.now().isoformat()
                }, f, ensure_ascii=False, indent=2)
            
            logger.info(f"‚úÖ –û—Ç–ª–∞–¥–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {ocr_debug_file}")
        
        logger.info(f"‚úÖ PDF –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ: {len(aggregated_resources)} —Ç–∏–ø–æ–≤ —Ä–µ—Å—É—Ä—Å–æ–≤")
        return result
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF —á–µ—Ä–µ–∑ OCR: {e}")
        return None


def save_debug_data(
    data: Dict[str, Any],
    batch_id: str,
    resource_type: str,
    debug_dir: Path,
    operation: str = "unknown"
) -> Optional[Path]:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç–ª–∞–¥–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
    
    –ë–õ–û–ö 3.2: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–ª–∞–¥–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    
    Args:
        data: –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        batch_id: ID –∑–∞–≥—Ä—É–∑–∫–∏
        resource_type: –¢–∏–ø —Ä–µ—Å—É—Ä—Å–∞
        debug_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        operation: –ù–∞–∑–≤–∞–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
    
    Returns:
        –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É –∏–ª–∏ None
    """
    try:
        debug_dir.mkdir(parents=True, exist_ok=True)
        
        debug_file = debug_dir / f"{batch_id}_{resource_type}_{operation}_debug.json"
        
        with open(debug_file, 'w', encoding='utf-8') as f:
            json.dump({
                "batch_id": batch_id,
                "resource_type": resource_type,
                "operation": operation,
                "data": data,
                "timestamp": datetime.now().isoformat()
            }, f, ensure_ascii=False, indent=2)
        
        logger.debug(f"–û—Ç–ª–∞–¥–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {debug_file}")
        return debug_file
        
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–ª–∞–¥–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {e}")
        return None


def log_execution_step(
    batch_id: str,
    step: str,
    status: str,
    details: Optional[Dict[str, Any]] = None,
    log_file: Optional[Path] = None
):
    """
    –õ–æ–≥–∏—Ä—É–µ—Ç —à–∞–≥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤ execution_log.jsonl.
    
    –ë–õ–û–ö 3.2: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞
    
    Args:
        batch_id: ID –∑–∞–≥—Ä—É–∑–∫–∏
        step: –ù–∞–∑–≤–∞–Ω–∏–µ —à–∞–≥–∞
        status: –°—Ç–∞—Ç—É—Å (success, error, warning)
        details: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ—Ç–∞–ª–∏
        log_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –ª–æ–≥–∞
    """
    try:
        if log_file:
            log_file.parent.mkdir(parents=True, exist_ok=True)
            
            log_entry = {
                "timestamp": datetime.now().isoformat(),
                "batch_id": batch_id,
                "step": step,
                "status": status,
                "details": details or {}
            }
            
            with open(log_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")
            
            logger.debug(f"–õ–æ–≥ –∑–∞–ø–∏—Å–∞–Ω: {step} ({status})")
        
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –ª–æ–≥: {e}")

