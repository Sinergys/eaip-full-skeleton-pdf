"""
–ú–æ–¥—É–ª—å –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Å–ø–æ—Ä—Ç–∞.

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω–æ—Ç—É –¥–∞–Ω–Ω—ã—Ö, –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ –∏ —Ñ–∞–π–ª–æ–≤,
–≤—ã—á–∏—Å–ª—è–µ—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–∞—Å–ø–æ—Ä—Ç–∞.
"""

import logging
import json
import os
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path

from config.required_data_matrix import (
    REQUIRED_DATA_MATRIX,
    MINIMAL_REQUIREMENTS,
    get_required_resources,
    get_optional_resources,
    get_resource_config,
)
from domain.passport_requirements import (
    PASSPORT_SHEET_REQUIREMENTS,
    validate_sheet_data,
)
from utils.energy_aggregator import aggregate_from_db_json
from utils.resource_classifier import ResourceClassifier
import database

logger = logging.getLogger(__name__)


def validate_generation_readiness(enterprise_id: int) -> Dict[str, Any]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Å–ø–æ—Ä—Ç–∞.

    Args:
        enterprise_id: ID –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏:
        {
            "ready": bool,
            "completeness_score": float,  # 0.0-1.0
            "missing_resources": List[str],
            "missing_files": List[str],
            "available_resources": List[str],
            "available_files": List[str],
            "warnings": List[str],
            "progress_percentage": int,
            "required_resources_status": Dict[str, Dict],
            "optional_resources_status": Dict[str, Dict],
            "sheet_validation": Dict[str, Dict],  # –ù–û–í–û–ï: –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ –ª–∏—Å—Ç–∞–º
            "missing_sheet_data": List[str]  # –ù–û–í–û–ï: –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ª–∏—Å—Ç–æ–≤
        }
    """
    try:
        logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è {enterprise_id}")

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è
        uploads = database.list_uploads_for_enterprise(enterprise_id)

        if not uploads:
            return {
                "ready": False,
                "completeness_score": 0.0,
                "missing_resources": get_required_resources(),
                "missing_files": [],
                "available_resources": [],
                "available_files": [],
                "warnings": ["–ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"],
                "progress_percentage": 0,
                "required_resources_status": {},
                "optional_resources_status": {},
            }

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        available_files = []
        file_to_resource_map: Dict[str, str] = {}

        for upload in uploads:
            filename = upload.get("filename", "")
            status = upload.get("status", "")

            # –£—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            if status == "success" and filename:
                available_files.append(filename)

                # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å raw_json –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
                raw_json = None
                try:
                    upload_record = database.get_upload_by_batch(upload.get("batch_id"))
                    if upload_record:
                        raw_json = upload_record.get("raw_json")
                except Exception as e:
                    logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å raw_json –¥–ª—è {filename}: {e}")

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ—Å—É—Ä—Å —Å —É—á–µ—Ç–æ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–¥–∏–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä)
                resource = ResourceClassifier.classify(filename, raw_json)
                if resource and resource != "other":
                    file_to_resource_map[filename] = resource
                    logger.debug(f"–§–∞–π–ª {filename} –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∫–∞–∫ —Ä–µ—Å—É—Ä—Å: {resource}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        available_resources = set()
        aggregated_data = _get_aggregated_data_for_enterprise(enterprise_id)

        if aggregated_data and "resources" in aggregated_data:
            resources = aggregated_data["resources"]
            for resource_name, resource_data in resources.items():
                if resource_data and isinstance(resource_data, dict):
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ö–æ—Ç—è –±—ã –≤ –æ–¥–Ω–æ–º –∫–≤–∞—Ä—Ç–∞–ª–µ
                    quarters = [
                        q
                        for q in resource_data.keys()
                        if q and isinstance(resource_data[q], dict)
                    ]
                    if quarters:
                        available_resources.add(resource_name)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –∏–º–µ–Ω–∞–º —Ñ–∞–π–ª–æ–≤
        for filename, resource in file_to_resource_map.items():
            available_resources.add(resource)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö JSON —Ñ–∞–π–ª–æ–≤ (nodes, equipment, envelope)
        # –≠—Ç–∏ —Ä–µ—Å—É—Ä—Å—ã –Ω–µ –ø–æ–ø–∞–¥–∞—é—Ç –≤ aggregated_data["resources"]
        AGGREGATED_DIR = Path(
            os.getenv(
                "AGGREGATED_DIR",
                os.path.join(os.getenv("INBOX_DIR", "/data/inbox"), "aggregated"),
            )
        )
        for batch_id in [u.get("batch_id") for u in uploads if u.get("batch_id")]:
            if (AGGREGATED_DIR / f"{batch_id}_nodes.json").exists():
                available_resources.add("nodes")
            if (AGGREGATED_DIR / f"{batch_id}_equipment.json").exists():
                available_resources.add("equipment")
            if (AGGREGATED_DIR / f"{batch_id}_envelope.json").exists():
                available_resources.add("envelope")

        available_resources_list = sorted(list(available_resources))

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã
        required_resources = get_required_resources()
        missing_resources = [
            resource
            for resource in required_resources
            if resource not in available_resources
        ]

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Ñ–∞–π–ª—ã
        missing_files = _get_missing_files_for_resources(
            missing_resources, available_files
        )

        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Ä–µ—Å—É—Ä—Å–æ–≤
        required_resources_status = _get_resources_status(
            required_resources, available_resources, aggregated_data
        )
        optional_resources_status = _get_resources_status(
            get_optional_resources(), available_resources, aggregated_data
        )

        # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
        completeness_score = _calculate_completeness_score(
            required_resources,
            available_resources_list,
            missing_resources,
            aggregated_data,
        )

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        warnings = _generate_warnings(
            missing_resources, missing_files, available_resources_list, aggregated_data
        )

        # –ù–û–í–û–ï: –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ª–∏—Å—Ç–∞
        sheet_validation, missing_sheet_data = _validate_sheets_data(
            enterprise_id, aggregated_data, uploads
        )

        # –î–æ–±–∞–≤–ª—è–µ–º –æ—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ª–∏—Å—Ç–æ–≤ –≤ warnings
        for sheet_name, validation_result in sheet_validation.items():
            if not validation_result.get("valid", True):
                errors = validation_result.get("errors", [])
                warnings.extend(errors)
                missing_sheet_data.extend([f"{sheet_name}: {err}" for err in errors])

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å (—É—á–∏—Ç—ã–≤–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é –ª–∏—Å—Ç–æ–≤)
        ready = (
            len(missing_resources) == 0
            and completeness_score >= MINIMAL_REQUIREMENTS["min_completeness_score"]
            and all(
                result.get("valid", True)
                for result in sheet_validation.values()
                if result.get("required", False)
            )
        )

        progress_percentage = int(completeness_score * 100)

        result = {
            "ready": ready,
            "completeness_score": round(completeness_score, 2),
            "missing_resources": missing_resources,
            "missing_files": missing_files,
            "available_resources": available_resources_list,
            "available_files": available_files,
            "warnings": warnings,
            "progress_percentage": progress_percentage,
            "required_resources_status": required_resources_status,
            "optional_resources_status": optional_resources_status,
            "sheet_validation": sheet_validation,
            "missing_sheet_data": missing_sheet_data,
        }

        logger.info(
            f"–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏: ready={ready}, "
            f"completeness={completeness_score:.2f}, "
            f"missing={missing_resources}"
        )

        return result
    except Exception as e:
        logger.error(
            f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –¥–ª—è –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è {enterprise_id}: {e}",
            exc_info=True,
        )
        return {
            "ready": False,
            "completeness_score": 0.0,
            "missing_resources": get_required_resources(),
            "missing_files": [],
            "available_resources": [],
            "available_files": [],
            "warnings": [f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏: {str(e)}"],
            "progress_percentage": 0,
            "required_resources_status": {},
            "optional_resources_status": {},
        }


def _get_aggregated_data_for_enterprise(enterprise_id: int) -> Optional[Dict[str, Any]]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è.

    –ü—Ä–æ–±—É–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—Å–µ—Ö –∑–∞–≥—Ä—É–∑–æ–∫ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è.
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ ingest
    ingest_path = Path(__file__).resolve().parent.parent
    INBOX_DIR = Path(os.getenv("INBOX_DIR", str(ingest_path / "data" / "inbox")))
    AGGREGATED_DIR = Path(os.getenv("AGGREGATED_DIR", str(INBOX_DIR / "aggregated")))
    AGGREGATED_DIR.mkdir(parents=True, exist_ok=True)

    uploads = database.list_uploads_for_enterprise(enterprise_id)

    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—Å–µ—Ö —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–≥—Ä—É–∑–æ–∫
    all_aggregated = {
        "resources": {
            "electricity": {},
            "gas": {},
            "water": {},
            "fuel": {},
            "coal": {},
            "heat": {},
            "production": {},
        }
    }

    for upload in uploads:
        batch_id = upload.get("batch_id")
        status = upload.get("status")
        filename = upload.get("filename", "unknown")

        if status == "success" and batch_id:
            try:
                logger.debug(
                    f"üîç [DIAG] –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {filename} (batch_id: {batch_id[:8]}...)"
                )

                # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–µ—Ä–µ–∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª
                aggregated_file = AGGREGATED_DIR / f"{batch_id}_aggregated.json"
                aggregated = None

                if aggregated_file.exists():
                    try:
                        logger.info(
                            f"üìÇ [DIAG] –ù–∞–π–¥–µ–Ω –ø–µ—Ä–µ–∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª: {aggregated_file.name}"
                        )
                        with open(aggregated_file, "r", encoding="utf-8") as f:
                            aggregated = json.load(f)
                        logger.info(
                            f"‚úÖ [DIAG] –ó–∞–≥—Ä—É–∂–µ–Ω –ø–µ—Ä–µ–∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è {filename}"
                        )
                    except Exception as e:
                        logger.warning(
                            f"‚ö†Ô∏è [DIAG] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–µ—Ä–µ–∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ {aggregated_file.name}: {e}"
                        )

                # –ï—Å–ª–∏ –ø–µ—Ä–µ–∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –Ω–µ—Ç, –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º –∏–∑ –ë–î
                if not aggregated:
                    upload_record = database.get_upload_by_batch(batch_id)
                    if upload_record and upload_record.get("raw_json"):
                        raw_json = upload_record["raw_json"]
                        logger.debug(
                            f"üìä [DIAG] raw_json –Ω–∞–π–¥–µ–Ω, –∫–ª—é—á–∏: {list(raw_json.keys())}"
                        )
                        logger.info(f"üîÑ [DIAG] –ê–≥—Ä–µ–≥–∏—Ä—É—é –∏–∑ –ë–î –¥–ª—è {filename}")
                        aggregated = aggregate_from_db_json(raw_json)
                    else:
                        logger.debug(f"‚ö†Ô∏è [DIAG] –ù–µ—Ç raw_json –¥–ª—è {filename}")

                if aggregated and "resources" in aggregated:
                    logger.info(
                        f"‚úÖ [DIAG] –ê–≥—Ä–µ–≥–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞ –¥–ª—è {filename}: —Ä–µ—Å—É—Ä—Å—ã={list(aggregated['resources'].keys())}"
                    )
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—Å–µ—Ö –∑–∞–≥—Ä—É–∑–æ–∫
                    for resource_name, resource_data in aggregated["resources"].items():
                        if resource_data and isinstance(resource_data, dict):
                            if resource_name not in all_aggregated["resources"]:
                                all_aggregated["resources"][resource_name] = {}
                            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–≤–∞—Ä—Ç–∞–ª—ã (–Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º, –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å)
                            for quarter, quarter_data in resource_data.items():
                                if quarter_data and isinstance(quarter_data, dict):
                                    months_count = len(quarter_data.get("months", []))
                                    quarter_totals = quarter_data.get(
                                        "quarter_totals", {}
                                    )
                                    logger.info(
                                        f"üìä [DIAG] –†–µ—Å—É—Ä—Å {resource_name}, –∫–≤–∞—Ä—Ç–∞–ª {quarter}: "
                                        f"{months_count} –º–µ—Å—è—Ü–µ–≤, quarter_totals={list(quarter_totals.keys()) if quarter_totals else '–ø—É—Å—Ç–æ'}, "
                                        f"active_kwh={quarter_totals.get('active_kwh') if quarter_totals else '–Ω–µ—Ç'}"
                                    )
                                    # –ï—Å–ª–∏ –∫–≤–∞—Ä—Ç–∞–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –æ–±—ä–µ–¥–∏–Ω—è–µ–º –º–µ—Å—è—Ü—ã
                                    if (
                                        quarter
                                        in all_aggregated["resources"][resource_name]
                                    ):
                                        existing_quarter = all_aggregated["resources"][
                                            resource_name
                                        ][quarter]
                                        existing_months = existing_quarter.get(
                                            "months", []
                                        )
                                        new_months = quarter_data.get("months", [])
                                        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –º–µ—Å—è—Ü—ã
                                        existing_quarter["months"] = (
                                            existing_months + new_months
                                        )
                                        # –û–±–Ω–æ–≤–ª—è–µ–º quarter_totals, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å –≤ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                                        if quarter_totals:
                                            existing_quarter["quarter_totals"] = (
                                                quarter_totals
                                            )
                                        # –í–ê–ñ–ù–û: –°–æ—Ö—Ä–∞–Ω—è–µ–º by_usage, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å –≤ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                                        new_by_usage = quarter_data.get("by_usage")
                                        if new_by_usage and isinstance(
                                            new_by_usage, dict
                                        ):
                                            existing_quarter["by_usage"] = new_by_usage
                                            logger.debug(
                                                f"‚úÖ [DIAG] –°–æ—Ö—Ä–∞–Ω–µ–Ω by_usage –¥–ª—è {resource_name} {quarter}: {list(new_by_usage.keys())}"
                                            )
                                        logger.debug(
                                            f"üîÑ [DIAG] –û–±—ä–µ–¥–∏–Ω–µ–Ω—ã –º–µ—Å—è—Ü—ã –¥–ª—è {resource_name} {quarter}: {len(existing_months)} + {len(new_months)} = {len(existing_quarter['months'])}"
                                        )
                                    else:
                                        all_aggregated["resources"][resource_name][
                                            quarter
                                        ] = quarter_data
                                        # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ by_usage –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏
                                        if quarter_data.get("by_usage"):
                                            logger.debug(
                                                f"‚úÖ [DIAG] –î–æ–±–∞–≤–ª–µ–Ω –∫–≤–∞—Ä—Ç–∞–ª {resource_name} {quarter} —Å by_usage: {list(quarter_data.get('by_usage', {}).keys())}"
                                            )
                                        else:
                                            logger.debug(
                                                f"‚ö†Ô∏è [DIAG] –î–æ–±–∞–≤–ª–µ–Ω –∫–≤–∞—Ä—Ç–∞–ª {resource_name} {quarter} –ë–ï–ó by_usage"
                                            )
                elif aggregated:
                    logger.warning(
                        f"‚ö†Ô∏è [DIAG] –ê–≥—Ä–µ–≥–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å –¥–ª—è {filename}: –Ω–µ—Ç 'resources' –≤ aggregated"
                    )
                else:
                    logger.debug(f"‚ö†Ô∏è [DIAG] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {filename}")
            except Exception as e:
                logger.warning(
                    f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ batch_id {batch_id}: {e}",
                    exc_info=True,
                )
                continue

    # –í—ã—á–∏—Å–ª—è–µ–º –∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã–µ –∏—Ç–æ–≥–∏ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    logger.info("üîç [DIAG] –ü–µ—Ä–µ–¥ —Ä–∞—Å—á–µ—Ç–æ–º –∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã—Ö –∏—Ç–æ–≥–æ–≤ –≤ –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–µ")
    logger.info(
        f"üìä [DIAG] –†–µ—Å—É—Ä—Å—ã –ø–µ—Ä–µ–¥ —Ä–∞—Å—á–µ—Ç–æ–º: {list(all_aggregated['resources'].keys())}"
    )
    for resource_name, resource_data in all_aggregated["resources"].items():
        if resource_data:
            logger.info(f"  - {resource_name}: {len(resource_data)} –∫–≤–∞—Ä—Ç–∞–ª–æ–≤")
            for quarter, quarter_data in resource_data.items():
                months_count = len(quarter_data.get("months", []))
                logger.debug(f"    ‚îî‚îÄ {quarter}: {months_count} –º–µ—Å—è—Ü–µ–≤")

    from utils.energy_aggregator import _compute_quarter_totals

    _compute_quarter_totals(all_aggregated["resources"])

    # –ö–†–ò–¢–ò–ß–ù–û: –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º canonical by_usage –ø–æ –∫–≤–∞—Ä—Ç–∞–ª–∞–º –¥–ª—è electricity
    # –≠—Ç–æ –Ω—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å –î–û –≤–∞–ª–∏–¥–∞—Ü–∏–∏, —á—Ç–æ–±—ã –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –≤–∏–¥–µ–ª by_usage –≤ –∫–≤–∞—Ä—Ç–∞–ª–∞—Ö
    _distribute_canonical_by_usage_to_quarters(all_aggregated, enterprise_id, uploads)

    logger.info("‚úÖ [DIAG] –ü–æ—Å–ª–µ —Ä–∞—Å—á–µ—Ç–∞ –∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã—Ö –∏—Ç–æ–≥–æ–≤ –≤ –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–µ")
    for resource_name, resource_data in all_aggregated["resources"].items():
        if resource_data:
            for quarter, quarter_data in resource_data.items():
                quarter_totals = quarter_data.get("quarter_totals", {})
                if quarter_totals:
                    logger.info(
                        f"  - {resource_name} {quarter}: quarter_totals={list(quarter_totals.keys())}"
                    )
                else:
                    logger.warning(
                        f"  ‚ö†Ô∏è {resource_name} {quarter}: quarter_totals –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç!"
                    )

                # –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ by_usage –ø–æ—Å–ª–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏—Ç–æ–≥–æ–≤
                by_usage = quarter_data.get("by_usage")
                if by_usage and isinstance(by_usage, dict) and len(by_usage) > 0:
                    logger.debug(
                        f"  ‚úÖ {resource_name} {quarter}: by_usage —Å–æ—Ö—Ä–∞–Ω–µ–Ω - {list(by_usage.keys())}"
                    )
                elif resource_name == "electricity":
                    logger.warning(
                        f"  ‚ö†Ô∏è {resource_name} {quarter}: by_usage –û–¢–°–£–¢–°–¢–í–£–ï–¢ –ø–æ—Å–ª–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏—Ç–æ–≥–æ–≤!"
                    )
                    logger.warning(
                        "     –≠—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –æ—à–∏–±–∫–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è –ª–∏—Å—Ç–∞ '04_–ë–∞–ª–∞–Ω—Å'"
                    )

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—è –±—ã –∫–∞–∫–∏–µ-—Ç–æ –¥–∞–Ω–Ω—ã–µ
    has_data = any(
        resource_data and isinstance(resource_data, dict) and len(resource_data) > 0
        for resource_data in all_aggregated["resources"].values()
    )

    if not has_data:
        logger.warning(
            "‚ö†Ô∏è [DIAG] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö –∑–∞–≥—Ä—É–∑–æ–∫"
        )

    return all_aggregated if has_data else None


def _distribute_canonical_by_usage_to_quarters(
    all_aggregated: Dict[str, Any], enterprise_id: int, uploads: List[Dict[str, Any]]
) -> None:
    """
    –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç canonical by_usage –ø–æ –∫–≤–∞—Ä—Ç–∞–ª–∞–º –¥–ª—è electricity.

    –≠—Ç–æ –Ω—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å –î–û –≤–∞–ª–∏–¥–∞—Ü–∏–∏, —á—Ç–æ–±—ã –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –≤–∏–¥–µ–ª by_usage –≤ –∫–≤–∞—Ä—Ç–∞–ª–∞—Ö.
    """
    try:
        from settings.excel_semantic_settings import get_excel_semantic_mode
        from utils.canonical_collector import collect_canonical_from_workbook
        from utils.canonical_to_passport import canonical_to_passport_payload
        from ai.ai_excel_semantic_parser import CanonicalSourceData

        excel_ai_mode_runtime = get_excel_semantic_mode()
        logger.info(f"üîç –†–µ–∂–∏–º canonical: {excel_ai_mode_runtime}")

        # –ü—Ä–æ–±—É–µ–º —Å–æ–±—Ä–∞—Ç—å canonical –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ä–µ–∂–∏–º–∞
        # –ï—Å–ª–∏ —Ä–µ–∂–∏–º "off", collect_canonical_from_workbook –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å None,
        # –Ω–æ –º—ã –≤—Å–µ —Ä–∞–≤–Ω–æ –ø–æ–ø—Ä–æ–±—É–µ–º
        if excel_ai_mode_runtime == "off":
            logger.warning(
                "‚ö†Ô∏è –†–µ–∂–∏–º canonical: 'off'. –ü–æ–ø—ã—Ç–∫–∞ —Å–æ–±—Ä–∞—Ç—å canonical –º–æ–∂–µ—Ç –Ω–µ —É–¥–∞—Ç—å—Å—è. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å EXCEL_SEMANTIC_AI_MODE=assist"
            )

        logger.info("üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ canonical –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è by_usage")

        # –ò—â–µ–º canonical –¥–∞–Ω–Ω—ã–µ –≤ –∑–∞–≥—Ä—É–∑–∫–∞—Ö –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è
        # –°–æ–±–∏—Ä–∞–µ–º canonical –∏–∑ –í–°–ï–• —Ñ–∞–π–ª–æ–≤ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –∏–∑ –æ–¥–Ω–æ–≥–æ
        global_canonical = CanonicalSourceData()
        found_equipment = False

        for upload in uploads:
            batch_id = upload.get("batch_id")
            status = upload.get("status")
            if status == "success" and batch_id:
                try:
                    upload_record = database.get_upload_by_batch(batch_id)
                    if upload_record and upload_record.get("file_path"):
                        file_path = upload_record["file_path"]
                        if file_path and Path(file_path).exists():
                            # –ü—Ä–æ–±—É–µ–º —Å–æ–±—Ä–∞—Ç—å canonical –∏–∑ —Ñ–∞–π–ª–∞
                            canonical = collect_canonical_from_workbook(file_path)
                            if canonical:
                                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
                                if canonical.equipment:
                                    global_canonical.equipment.extend(
                                        canonical.equipment
                                    )
                                    found_equipment = True
                                    logger.debug(
                                        f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(canonical.equipment)} –µ–¥–∏–Ω–∏—Ü –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –≤ {Path(file_path).name}"
                                    )
                                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ—Å—É—Ä—Å—ã
                                if canonical.resources:
                                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ—Å—É—Ä—Å—ã, –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç - –±–æ–ª–µ–µ –ø–æ–∑–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ
                                    for resource in canonical.resources:
                                        existing = next(
                                            (
                                                r
                                                for r in global_canonical.resources
                                                if r.resource == resource.resource
                                            ),
                                            None,
                                        )
                                        if existing:
                                            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ä–µ—Å—É—Ä—Å
                                            if (
                                                resource.series
                                                and resource.series.annual
                                            ):
                                                existing.series = resource.series
                                        else:
                                            global_canonical.resources.append(resource)
                except Exception as e:
                    logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ canonical –∏–∑ {batch_id}: {e}")
                    continue

        # –ï—Å–ª–∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —á–µ—Ä–µ–∑ canonical (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä–µ–∂–∏–º "off"),
        # –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ equipment JSON —Ñ–∞–π–ª–æ–≤
        if not found_equipment or not global_canonical.equipment:
            logger.info(
                "–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —á–µ—Ä–µ–∑ canonical, –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ JSON —Ñ–∞–π–ª–æ–≤"
            )
            ingest_path = Path(__file__).resolve().parent.parent
            INBOX_DIR = Path(
                os.getenv("INBOX_DIR", str(ingest_path / "data" / "inbox"))
            )
            AGGREGATED_DIR = Path(
                os.getenv("AGGREGATED_DIR", str(INBOX_DIR / "aggregated"))
            )

            for upload in uploads:
                batch_id = upload.get("batch_id")
                if batch_id:
                    equipment_json_path = AGGREGATED_DIR / f"{batch_id}_equipment.json"
                    if equipment_json_path.exists():
                        try:
                            equipment_data = json.loads(
                                equipment_json_path.read_text(encoding="utf-8")
                            )
                            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º equipment JSON –≤ EquipmentItem
                            equipment_items = _convert_equipment_json_to_items(
                                equipment_data
                            )
                            if equipment_items:
                                global_canonical.equipment.extend(equipment_items)
                                found_equipment = True
                                logger.info(
                                    f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(equipment_items)} –µ–¥–∏–Ω–∏—Ü –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –∏–∑ {equipment_json_path.name}"
                                )
                                break
                        except Exception as e:
                            logger.debug(
                                f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ equipment JSON –∏–∑ {batch_id}: {e}"
                            )
                            continue

        if not found_equipment or not global_canonical.equipment:
            logger.warning("‚ö†Ô∏è Canonical –¥–∞–Ω–Ω—ã–µ —Å –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ–º –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            logger.warning("   –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
            logger.warning(
                "   1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ EXCEL_SEMANTIC_AI_MODE=assist –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è canonical mode"
            )
            logger.warning(
                "   2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω"
            )
            logger.warning(
                "   3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ {batch_id}_equipment.json –≤ aggregated –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"
            )
            logger.info(
                "üîÑ –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–º –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ–º by_usage –±–µ–∑ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è"
            )

        equipment_count = (
            len(global_canonical.equipment) if global_canonical.equipment else 0
        )
        if equipment_count > 0:
            logger.info(
                f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {equipment_count} –µ–¥–∏–Ω–∏—Ü –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è by_usage"
            )
        else:
            logger.info(
                "‚ö†Ô∏è –û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ by_usage"
            )

        # –ü–æ–ª—É—á–∞–µ–º annual_total –¥–ª—è electricity –∏–∑ aggregated –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç –≤ canonical
        electricity_data = all_aggregated.get("resources", {}).get("electricity", {})
        if not electricity_data:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö electricity –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è by_usage")
            return

        annual_total = None

        # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ ANNUAL
        annual_data = electricity_data.get("ANNUAL")
        if annual_data and isinstance(annual_data, dict):
            annual_totals = annual_data.get("quarter_totals", {})
            annual_total = annual_totals.get("active_kwh")

        # –ï—Å–ª–∏ –Ω–µ—Ç –≤ ANNUAL, –≤—ã—á–∏—Å–ª—è–µ–º —Å—É–º–º—É –ø–æ –≤—Å–µ–º –∫–≤–∞—Ä—Ç–∞–ª–∞–º
        if not annual_total:
            total_consumption = 0.0
            for quarter_key, quarter_data in electricity_data.items():
                if quarter_key == "ANNUAL":
                    continue
                if isinstance(quarter_data, dict):
                    quarter_totals = quarter_data.get("quarter_totals", {})
                    if quarter_totals:
                        quarter_total = quarter_totals.get("active_kwh", 0)
                        if quarter_total:
                            total_consumption += float(quarter_total)
            if total_consumption > 0:
                annual_total = total_consumption
                logger.info(
                    f"‚úÖ Annual total –≤—ã—á–∏—Å–ª–µ–Ω –∏–∑ –∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {annual_total}"
                )

        if not annual_total or annual_total <= 0:
            logger.warning(
                "‚ö†Ô∏è Annual total –¥–ª—è electricity –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ —Ä–∞–≤–µ–Ω 0. –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã—á–∏—Å–ª–∏—Ç—å by_usage"
            )
            # –î–∞–∂–µ –±–µ–∑ annual_total, –ø–æ–ø—Ä–æ–±—É–µ–º —Å–æ–∑–¥–∞—Ç—å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π by_usage –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–≤–∞—Ä—Ç–∞–ª–∞
            _create_minimal_by_usage_for_quarters(electricity_data)
            return

        # –ï—Å–ª–∏ –µ—Å—Ç—å –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ, –ø—Ä–æ–±—É–µ–º –≤—ã—á–∏—Å–ª–∏—Ç—å canonical by_usage
        canonical_by_usage = None
        if equipment_count > 0:
            # –ï—Å–ª–∏ annual_total –Ω–∞–π–¥–µ–Ω, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –≤ canonical resources
            from ai.ai_excel_semantic_parser import ResourceEntry, TimeSeries

            existing_electricity = next(
                (r for r in global_canonical.resources if r.resource == "electricity"),
                None,
            )
            if existing_electricity:
                if (
                    not existing_electricity.series
                    or not existing_electricity.series.annual
                ):
                    existing_electricity.series = TimeSeries(annual=float(annual_total))
            else:
                global_canonical.resources.append(
                    ResourceEntry(
                        resource="electricity",
                        series=TimeSeries(annual=float(annual_total)),
                    )
                )
            logger.info(
                f"‚úÖ Annual total –¥–ª—è electricity –¥–æ–±–∞–≤–ª–µ–Ω –≤ canonical: {annual_total}"
            )

            canonical_source_data = global_canonical

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º canonical –≤ payload –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è by_usage
            try:
                canonical_payload = canonical_to_passport_payload(canonical_source_data)
                canonical_by_usage = (
                    canonical_payload.get("balance", {})
                    .get("by_usage", {})
                    .get("electricity")
                )

                if (
                    canonical_by_usage
                    and isinstance(canonical_by_usage, dict)
                    and len(canonical_by_usage) > 0
                ):
                    logger.info(
                        f"‚úÖ Canonical by_usage –Ω–∞–π–¥–µ–Ω: {list(canonical_by_usage.keys())}"
                    )
                else:
                    logger.warning(
                        "‚ö†Ô∏è Canonical by_usage –¥–ª—è electricity –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ payload, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ"
                    )
                    canonical_by_usage = None
            except Exception as e:
                logger.warning(
                    f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ canonical by_usage: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ"
                )
                canonical_by_usage = None

        # –ï—Å–ª–∏ canonical_by_usage –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        if not canonical_by_usage or not isinstance(canonical_by_usage, dict):
            logger.info("üîÑ –°–æ–∑–¥–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ by_usage")
            canonical_by_usage = _create_standard_by_usage_distribution(annual_total)
            logger.info(
                f"‚úÖ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ: {list(canonical_by_usage.keys())}"
            )

        # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â–µ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–æ –≤—Å–µ–º –∫–≤–∞—Ä—Ç–∞–ª–∞–º
        total_quarterly_consumption = 0.0
        for quarter_key, quarter_data in electricity_data.items():
            if quarter_key == "ANNUAL":
                continue
            if isinstance(quarter_data, dict):
                quarter_total = quarter_data.get("quarter_totals", {}).get(
                    "active_kwh", 0
                )
                if quarter_total:
                    total_quarterly_consumption += float(quarter_total)

        if total_quarterly_consumption <= 0:
            logger.warning(
                "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç—å by_usage: total_quarterly_consumption=0"
            )
            # –î–∞–∂–µ –ø—Ä–∏ –Ω—É–ª–µ–≤–æ–º –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–∏ —Å–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π by_usage
            _create_minimal_by_usage_for_quarters(electricity_data)
            return

        # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º by_usage –ø–æ –∫–≤–∞—Ä—Ç–∞–ª–∞–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—é
        distributed_count = 0
        for quarter_key, quarter_data in electricity_data.items():
            if quarter_key == "ANNUAL":
                continue
            if isinstance(quarter_data, dict):
                quarter_total = quarter_data.get("quarter_totals", {}).get(
                    "active_kwh", 0
                )
                if quarter_total and quarter_total > 0:
                    # –ü—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
                    quarter_ratio = float(quarter_total) / total_quarterly_consumption
                    quarter_by_usage = {
                        category: round(float(value) * quarter_ratio, 2)
                        for category, value in canonical_by_usage.items()
                    }
                    quarter_data["by_usage"] = quarter_by_usage
                    distributed_count += 1
                    logger.debug(
                        "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω by_usage –¥–ª—è electricity %s: %s (ratio=%.3f)",
                        quarter_key,
                        list(quarter_by_usage.keys()),
                        quarter_ratio,
                    )

        if distributed_count > 0:
            logger.info(
                "‚úÖ by_usage —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω –ø–æ %d –∫–≤–∞—Ä—Ç–∞–ª–∞–º electricity (annual_total=%.2f, quarterly_total=%.2f)",
                distributed_count,
                float(annual_total),
                total_quarterly_consumption,
            )
        else:
            logger.warning(
                "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç—å by_usage: –Ω–µ—Ç –∫–≤–∞—Ä—Ç–∞–ª–æ–≤ —Å –∞–∫—Ç–∏–≤–Ω—ã–º –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ–º"
            )
            # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π by_usage –∫–∞–∫ fallback
            _create_minimal_by_usage_for_quarters(electricity_data)

    except Exception as e:
        logger.warning(
            f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ canonical by_usage: {e}", exc_info=True
        )
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ —Å–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π by_usage –∫–∞–∫ fallback
        try:
            electricity_data = all_aggregated.get("resources", {}).get(
                "electricity", {}
            )
            if electricity_data and isinstance(electricity_data, dict):
                _create_minimal_by_usage_for_quarters(electricity_data)
                logger.info("‚úÖ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π by_usage —Å–æ–∑–¥–∞–Ω –∫–∞–∫ fallback –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏")
            else:
                logger.warning(
                    "‚ö†Ô∏è –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π by_usage: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö electricity"
                )
        except Exception as fallback_error:
            logger.error(
                f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ by_usage: {fallback_error}",
                exc_info=True,
            )


def _create_standard_by_usage_distribution(annual_total: float) -> Dict[str, float]:
    """
    –°–æ–∑–¥–∞–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ by_usage –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–≥–¥–∞ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–ª–∏ canonical by_usage –Ω–µ –≤—ã—á–∏—Å–ª–µ–Ω.

    Args:
        annual_total: –ì–æ–¥–æ–≤–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —ç–ª–µ–∫—Ç—Ä–æ—ç–Ω–µ—Ä–≥–∏–∏ (–∫–í—Ç¬∑—á)

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    """
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–π:
    # - technological: 50% - —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ
    # - production: 30% - –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã
    # - own_needs: 15% - —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –Ω—É–∂–¥—ã (–æ—Å–≤–µ—â–µ–Ω–∏–µ, –≤–µ–Ω—Ç–∏–ª—è—Ü–∏—è –∏ —Ç.–¥.)
    # - household: 5% - —Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω–æ-–±—ã—Ç–æ–≤—ã–µ –Ω—É–∂–¥—ã

    return {
        "technological": round(annual_total * 0.50, 2),
        "production": round(annual_total * 0.30, 2),
        "own_needs": round(annual_total * 0.15, 2),
        "household": round(annual_total * 0.05, 2),
    }


def _create_minimal_by_usage_for_quarters(electricity_data: Dict[str, Any]) -> None:
    """
    –°–æ–∑–¥–∞–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π by_usage –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–≤–∞—Ä—Ç–∞–ª–∞ electricity.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ –∞–≤–∞—Ä–∏–π–Ω—ã–π fallback, –∫–æ–≥–¥–∞ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã—á–∏—Å–ª–∏—Ç—å –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ.

    Args:
        electricity_data: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ electricity –ø–æ –∫–≤–∞—Ä—Ç–∞–ª–∞–º
    """
    logger.info("üîß –°–æ–∑–¥–∞–Ω–∏–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ by_usage –¥–ª—è –≤—Å–µ—Ö –∫–≤–∞—Ä—Ç–∞–ª–æ–≤ electricity")

    distributed_count = 0
    for quarter_key, quarter_data in electricity_data.items():
        if quarter_key == "ANNUAL":
            continue
        if not isinstance(quarter_data, dict):
            continue

        quarter_totals = quarter_data.get("quarter_totals", {})
        active_kwh = quarter_totals.get("active_kwh", 0) if quarter_totals else 0

        if active_kwh and active_kwh > 0:
            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è –∫–≤–∞—Ä—Ç–∞–ª–∞
            by_usage = {
                "technological": round(active_kwh * 0.50, 2),
                "production": round(active_kwh * 0.30, 2),
                "own_needs": round(active_kwh * 0.15, 2),
                "household": round(active_kwh * 0.05, 2),
            }

            quarter_data["by_usage"] = by_usage
            distributed_count += 1
            logger.debug(
                f"‚úÖ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π by_usage —Å–æ–∑–¥–∞–Ω –¥–ª—è {quarter_key}: {by_usage}"
            )
        else:
            logger.debug(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω –∫–≤–∞—Ä—Ç–∞–ª {quarter_key}: active_kwh={active_kwh}")

    if distributed_count > 0:
        logger.info(f"‚úÖ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π by_usage —Å–æ–∑–¥–∞–Ω –¥–ª—è {distributed_count} –∫–≤–∞—Ä—Ç–∞–ª–æ–≤")
    else:
        logger.warning(
            "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π by_usage: –Ω–µ—Ç –∫–≤–∞—Ä—Ç–∞–ª–æ–≤ —Å –∞–∫—Ç–∏–≤–Ω—ã–º –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ–º"
        )


def _get_missing_files_for_resources(
    missing_resources: List[str], available_files: List[str]
) -> List[str]:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Ñ–∞–π–ª—ã –¥–ª—è —Ä–µ—Å—É—Ä—Å–æ–≤."""
    missing_files = []

    for resource_name in missing_resources:
        config = get_resource_config(resource_name)
        patterns = config.get("file_patterns", [])

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ñ–∞–π–ª —Å –Ω—É–∂–Ω—ã–º –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º
        found = False
        for pattern in patterns:
            if any(pattern.lower() in filename.lower() for filename in available_files):
                found = True
                break

        if not found and patterns:
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –∫–∞–∫ –ø—Ä–∏–º–µ—Ä –Ω–µ–¥–æ—Å—Ç–∞—é—â–µ–≥–æ —Ñ–∞–π–ª–∞
            missing_files.append(patterns[0])

    return missing_files


def _get_resources_status(
    resources: List[str],
    available_resources: set,
    aggregated_data: Optional[Dict[str, Any]],
) -> Dict[str, Dict[str, Any]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å —Ä–µ—Å—É—Ä—Å–æ–≤."""
    status = {}

    for resource_name in resources:
        config = get_resource_config(resource_name)
        is_available = resource_name in available_resources

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–≤–∞—Ä—Ç–∞–ª–æ–≤
        quarters_count = 0
        if aggregated_data and "resources" in aggregated_data:
            resource_data = aggregated_data["resources"].get(resource_name)
            if resource_data and isinstance(resource_data, dict):
                quarters_count = len(
                    [
                        q
                        for q in resource_data.keys()
                        if q and isinstance(resource_data[q], dict)
                    ]
                )

        min_quarters = config.get("min_quarters", 4)
        has_enough_quarters = quarters_count >= min_quarters

        status[resource_name] = {
            "available": is_available,
            "quarters_count": quarters_count,
            "min_quarters": min_quarters,
            "has_enough_quarters": has_enough_quarters,
            "description": config.get("description", ""),
        }

    return status


def _calculate_completeness_score(
    required_resources: List[str],
    available_resources: List[str],
    missing_resources: List[str],
    aggregated_data: Optional[Dict[str, Any]],
) -> float:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö (0.0 - 1.0).

    –£—á–∏—Ç—ã–≤–∞–µ—Ç:
    - –ù–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ (–≤–µ—Å 60%)
    - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–≤–∞—Ä—Ç–∞–ª–æ–≤ –¥–∞–Ω–Ω—ã—Ö (–≤–µ—Å 30%)
    - –ù–∞–ª–∏—á–∏–µ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ (–≤–µ—Å 10%)
    """
    # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º —Ä–µ—Å—É—Ä—Å–∞–º
    if not required_resources:
        required_score = 1.0
    else:
        required_score = (len(required_resources) - len(missing_resources)) / len(
            required_resources
        )

    # –û—Ü–µ–Ω–∫–∞ –ø–æ –∫–≤–∞—Ä—Ç–∞–ª–∞–º
    quarters_score = 0.0
    if aggregated_data and "resources" in aggregated_data:
        total_quarters = 0
        total_min_quarters = 0

        for resource_name in required_resources:
            resource_data = aggregated_data["resources"].get(resource_name)
            config = get_resource_config(resource_name)
            min_quarters = config.get("min_quarters", 4)

            if resource_data and isinstance(resource_data, dict):
                quarters = len(
                    [
                        q
                        for q in resource_data.keys()
                        if q and isinstance(resource_data[q], dict)
                    ]
                )
                total_quarters += quarters
            total_min_quarters += min_quarters

        if total_min_quarters > 0:
            quarters_score = min(total_quarters / total_min_quarters, 1.0)

    # –û—Ü–µ–Ω–∫–∞ –ø–æ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º —Ä–µ—Å—É—Ä—Å–∞–º
    optional_resources = get_optional_resources()
    optional_score = 0.0
    if optional_resources:
        available_optional = len(
            [r for r in optional_resources if r in available_resources]
        )
        optional_score = available_optional / len(optional_resources)

    # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞
    completeness = required_score * 0.6 + quarters_score * 0.3 + optional_score * 0.1

    return max(0.0, min(1.0, completeness))


def _generate_warnings(
    missing_resources: List[str],
    missing_files: List[str],
    available_resources: List[str],
    aggregated_data: Optional[Dict[str, Any]],
) -> List[str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö."""
    warnings = []

    try:
        # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–∞—Ö
        if missing_resources:
            for resource_name in missing_resources:
                try:
                    config = get_resource_config(resource_name)
                    description = (
                        config.get("description", resource_name)
                        if config
                        else resource_name
                    )
                    warnings.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —Ä–µ—Å—É—Ä—Å: {description}")
                except Exception as e:
                    logger.warning(
                        f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Ä–µ—Å—É—Ä—Å–∞ {resource_name}: {e}"
                    )
                    warnings.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —Ä–µ—Å—É—Ä—Å: {resource_name}")

        # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —Ñ–∞–π–ª–∞—Ö
        if missing_files:
            warnings.append(f"–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª—ã: {', '.join(missing_files)}")

        # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –∫–≤–∞—Ä—Ç–∞–ª–æ–≤
        if aggregated_data and "resources" in aggregated_data:
            for resource_name, resource_data in aggregated_data["resources"].items():
                if resource_name not in available_resources:
                    continue

                try:
                    config = get_resource_config(resource_name)
                    min_quarters = config.get("min_quarters", 4) if config else 4

                    if resource_data and isinstance(resource_data, dict):
                        quarters = len(
                            [
                                q
                                for q in resource_data.keys()
                                if q and isinstance(resource_data[q], dict)
                            ]
                        )

                        if quarters < min_quarters:
                            warnings.append(
                                f"–†–µ—Å—É—Ä—Å {resource_name}: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–≤–∞—Ä—Ç–∞–ª–æ–≤ "
                                f"({quarters} –∏–∑ {min_quarters})"
                            )
                except Exception as e:
                    logger.warning(
                        f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–≤–∞—Ä—Ç–∞–ª–æ–≤ –¥–ª—è —Ä–µ—Å—É—Ä—Å–∞ {resource_name}: {e}"
                    )
                    continue

        if not warnings:
            warnings.append("–í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {e}", exc_info=True)
        warnings.append("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö")

    return warnings


def get_upload_checklist(enterprise_id: int) -> Dict[str, Any]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–µ–∫-–ª–∏—Å—Ç —Ç—Ä–µ–±—É–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è.

    Args:
        enterprise_id: ID –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —á–µ–∫-–ª–∏—Å—Ç–æ–º:
        {
            "required_files": List[Dict],
            "optional_files": List[Dict],
            "uploaded_files": List[str],
            "missing_required": List[str]
        }
    """
    try:
        uploads = database.list_uploads_for_enterprise(enterprise_id)
        uploaded_files = [
            u.get("filename", "") for u in uploads if u.get("status") == "success"
        ]
    except Exception as e:
        logger.error(
            f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —á–µ–∫-–ª–∏—Å—Ç–∞ –¥–ª—è –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è {enterprise_id}: {e}"
        )
        uploaded_files = []

    try:
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Ç—Ä–µ–±—É–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤
        required_files = []
        optional_files = []

        for category, resources in REQUIRED_DATA_MATRIX.items():
            for resource_name, config in resources.items():
                is_required = config.get("required", False)
                patterns = config.get("file_patterns", [])
                description = config.get("description", resource_name)

                # –£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ñ–∞–π–ª–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
                def file_matches_patterns(
                    fname: str, patts: List[str], res_name: str
                ) -> bool:
                    fname_lower = fname.lower()
                    fname_no_ext = (
                        fname_lower.rsplit(".", 1)[0]
                        if "." in fname_lower
                        else fname_lower
                    )

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
                    for pattern in patts:
                        pattern_lower = pattern.lower()
                        pattern_no_ext = (
                            pattern_lower.rsplit(".", 1)[0]
                            if "." in pattern_lower
                            else pattern_lower
                        )
                        if (
                            pattern_lower in fname_lower
                            or pattern_no_ext in fname_no_ext
                        ):
                            return True

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
                    keywords = config.get("keywords", [])
                    if any(keyword.lower() in fname_lower for keyword in keywords):
                        return True

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –µ—Å—Ç—å
                    for upload in uploads:
                        if upload.get("filename", "").lower() == fname_lower:
                            try:
                                upload_record = database.get_upload_by_batch(
                                    upload.get("batch_id")
                                )
                                if upload_record:
                                    raw_json = upload_record.get("raw_json")
                                    if raw_json:
                                        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
                                        from utils.content_analyzer import (
                                            analyze_file_content,
                                        )

                                        content_resource = analyze_file_content(
                                            raw_json, fname
                                        )
                                        if content_resource == res_name:
                                            return True
                            except Exception:
                                pass

                    return False

                file_info = {
                    "resource": resource_name,
                    "description": description,
                    "file_patterns": patterns,
                    "min_quarters": config.get("min_quarters", 4)
                    if category == "energy_resources"
                    else None,
                    "uploaded": any(
                        file_matches_patterns(filename, patterns, resource_name)
                        for filename in uploaded_files
                    ),
                }

                if is_required:
                    required_files.append(file_info)
                else:
                    optional_files.append(file_info)

        missing_required = [f["resource"] for f in required_files if not f["uploaded"]]

        return {
            "required_files": required_files,
            "optional_files": optional_files,
            "uploaded_files": uploaded_files,
            "missing_required": missing_required,
        }
    except Exception as e:
        logger.error(
            f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ —á–µ–∫-–ª–∏—Å—Ç–∞ –¥–ª—è –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è {enterprise_id}: {e}",
            exc_info=True,
        )
        return {
            "required_files": required_files,
            "optional_files": optional_files,
            "uploaded_files": uploaded_files if "uploaded_files" in locals() else [],
            "missing_required": get_required_resources(),
        }


def _validate_sheets_data(
    enterprise_id: int,
    aggregated_data: Optional[Dict[str, Any]],
    uploads: List[Dict[str, Any]],
) -> Tuple[Dict[str, Dict[str, Any]], List[str]]:
    """
    –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ª–∏—Å—Ç–∞ –ø–∞—Å–ø–æ—Ä—Ç–∞.

    Args:
        enterprise_id: ID –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è
        aggregated_data: –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        uploads: –°–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∑–æ–∫ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è

    Returns:
        (sheet_validation_dict, missing_sheet_data_list)
    """
    sheet_validation = {}
    missing_sheet_data = []

    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç–∏ –∫ JSON —Ñ–∞–π–ª–∞–º (–¥–æ–ª–∂–µ–Ω —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –ø—É—Ç–µ–º –≤ main.py)
    import os

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—É –∂–µ –ª–æ–≥–∏–∫—É, —á—Ç–æ –∏ –≤ main.py
    INBOX_DIR = os.getenv("INBOX_DIR", "/data/inbox")
    AGGREGATED_DIR = Path(
        os.getenv("AGGREGATED_DIR", os.path.join(INBOX_DIR, "aggregated"))
    )

    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ batch_id –¥–ª—è –ø–æ–∏—Å–∫–∞ JSON —Ñ–∞–π–ª–æ–≤
    batch_ids = [upload.get("batch_id") for upload in uploads if upload.get("batch_id")]

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    equipment_data = None
    envelope_data = None
    nodes_data = None
    usage_data = None

    for batch_id in batch_ids:
        if not batch_id:
            continue

        # Equipment
        if equipment_data is None:
            equipment_path = AGGREGATED_DIR / f"{batch_id}_equipment.json"
            if not equipment_path.exists():
                # –ü—Ä–æ–±—É–µ–º –æ–±—â–∏–π —Ñ–∞–π–ª
                equipment_path = AGGREGATED_DIR / "oborudovanie_equipment.json"
            if equipment_path.exists():
                try:
                    equipment_data = json.loads(
                        equipment_path.read_text(encoding="utf-8")
                    )
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ equipment JSON: {e}")

        # –†–∞—Å—á–µ—Ç —Ç–µ–ø–ª–æ–ø–æ—Ç–µ—Ä—å –ø–æ –∑–¥–∞–Ω–∏—è–º
        if envelope_data is None:
            envelope_path = AGGREGATED_DIR / f"{batch_id}_envelope.json"
            if not envelope_path.exists():
                envelope_path = AGGREGATED_DIR / "ograjdayuschie_envelope.json"
            if envelope_path.exists():
                try:
                    envelope_data = json.loads(
                        envelope_path.read_text(encoding="utf-8")
                    )
                except Exception as e:
                    logger.warning(
                        f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ JSON —Ä–∞—Å—á–µ—Ç–∞ —Ç–µ–ø–ª–æ–ø–æ—Ç–µ—Ä—å –ø–æ –∑–¥–∞–Ω–∏—è–º: {e}"
                    )

        # Nodes
        if nodes_data is None:
            nodes_path = AGGREGATED_DIR / f"{batch_id}_nodes.json"
            if nodes_path.exists():
                try:
                    nodes_data = json.loads(nodes_path.read_text(encoding="utf-8"))
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ nodes JSON: {e}")

    # Usage categories
    usage_path = AGGREGATED_DIR / "usage_categories.json"
    if usage_path.exists():
        try:
            usage_data = json.loads(usage_path.read_text(encoding="utf-8"))
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ usage JSON: {e}")

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    validation_data = {
        "resources": aggregated_data.get("resources", {}) if aggregated_data else {},
        "equipment": equipment_data,
        "envelope": envelope_data,
        "nodes": nodes_data,
        "usage": usage_data,
    }

    # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –ª–∏—Å—Ç
    for sheet_name, sheet_req in PASSPORT_SHEET_REQUIREMENTS.items():
        if not sheet_req.required:
            continue

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–æ–≥–æ –ª–∏—Å—Ç–∞
        sheet_data = _prepare_sheet_data(sheet_name, validation_data)

        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º
        is_valid, errors = validate_sheet_data(sheet_name, sheet_data)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ edge-–∫–µ–π—Å—ã –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ª–∏—Å—Ç–æ–≤
        if sheet_name in ["05_–î–∏–Ω–∞–º–∏–∫–∞", "–†–∞—Å—Ö–æ–¥ –Ω–∞ –µ–¥.–ø"]:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ, —Ç–æ –æ–Ω–æ –Ω–µ —Ä–∞–≤–Ω–æ –Ω—É–ª—é –≤–µ–∑–¥–µ
            production_data = sheet_data.get("resources", {}).get("production", {})
            if production_data:
                all_zero = all(
                    sum(
                        v
                        for v in q.get("quarter_totals", {}).values()
                        if isinstance(v, (int, float))
                    )
                    == 0
                    for q in production_data.values()
                    if isinstance(q, dict)
                )
                if all_zero and sheet_name == "–†–∞—Å—Ö–æ–¥ –Ω–∞ –µ–¥.–ø":
                    # –î–ª—è –ª–∏—Å—Ç–∞ "–†–∞—Å—Ö–æ–¥ –Ω–∞ –µ–¥.–ø" –Ω—É–ª–µ–≤–æ–µ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ –¥–æ–ø—É—Å—Ç–∏–º–æ (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è 0)
                    logger.info(
                        f"–õ–∏—Å—Ç '{sheet_name}': –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ –≤–µ–∑–¥–µ —Ä–∞–≤–Ω–æ 0 - —ç—Ç–æ –¥–æ–ø—É—Å—Ç–∏–º–æ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –ª–∏—Å—Ç–∞"
                    )
                elif all_zero:
                    errors.append(
                        f"–õ–∏—Å—Ç '{sheet_name}': –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ —Ä–∞–≤–Ω–æ 0 –≤–æ –≤—Å–µ—Ö –∫–≤–∞—Ä—Ç–∞–ª–∞—Ö - "
                        f"—É–¥–µ–ª—å–Ω—ã–π —Ä–∞—Å—Ö–æ–¥ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∞—Å—Å—á–∏—Ç–∞–Ω"
                    )

        sheet_validation[sheet_name] = {
            "valid": is_valid,
            "required": sheet_req.required,
            "errors": errors,
            "description": sheet_req.description,
        }

        if not is_valid:
            missing_sheet_data.extend(errors)

    return sheet_validation, missing_sheet_data


def _prepare_sheet_data(
    sheet_name: str, validation_data: Dict[str, Any]
) -> Dict[str, Any]:
    """
    –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ª–∏—Å—Ç–∞.

    Args:
        sheet_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞
        validation_data: –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

    Returns:
        –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ª–∏—Å—Ç–∞
    """
    result = {}

    # –ö–æ–ø–∏—Ä—É–µ–º —Ä–µ—Å—É—Ä—Å—ã
    resources = validation_data.get("resources", {})
    result["resources"] = resources

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–æ–ª–µ–π —Ç–∏–ø–∞ electricity.active_kwh, gas.volume_m3
    # –î–∞–Ω–Ω—ã–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ: resources.electricity.{quarter}.quarter_totals.active_kwh
    # –í–∞–ª–∏–¥–∞—Ç–æ—Ä –æ–∂–∏–¥–∞–µ—Ç: electricity.active_kwh (—Å–ª–æ–≤–∞—Ä—å –ø–æ –∫–≤–∞—Ä—Ç–∞–ª–∞–º –∏–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ)

    # –î–ª—è –ª–∏—Å—Ç–∞ Struktura pr2 –∏ –¥—Ä—É–≥–∏—Ö –ª–∏—Å—Ç–æ–≤ —Å –∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    if (
        "Struktura" in sheet_name
        or "–°—Ç—Ä—É–∫—Ç—É—Ä–∞" in sheet_name
        or "–î–∏–Ω–∞–º–∏–∫–∞" in sheet_name
    ):
        # –ò–∑–≤–ª–µ–∫–∞–µ–º electricity –¥–∞–Ω–Ω—ã–µ
        electricity_data = resources.get("electricity", {})
        logger.debug(
            f"–î–ª—è –ª–∏—Å—Ç–∞ '{sheet_name}': electricity_data keys: {list(electricity_data.keys()) if electricity_data else 'None'}"
        )
        if electricity_data:
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä–∏ –ø–æ –∫–≤–∞—Ä—Ç–∞–ª–∞–º –¥–ª—è active_kwh, reactive_kvarh
            active_kwh_by_quarter = {}
            reactive_kvarh_by_quarter = {}
            quarter_totals_by_quarter = {}

            for quarter, quarter_data in electricity_data.items():
                if isinstance(quarter_data, dict):
                    quarter_totals = quarter_data.get("quarter_totals", {})
                    if quarter_totals:
                        if "active_kwh" in quarter_totals:
                            active_kwh_by_quarter[quarter] = quarter_totals[
                                "active_kwh"
                            ]
                        if "reactive_kvarh" in quarter_totals:
                            reactive_kvarh_by_quarter[quarter] = quarter_totals[
                                "reactive_kvarh"
                            ]
                        quarter_totals_by_quarter[quarter] = quarter_totals
                    else:
                        # –ï—Å–ª–∏ quarter_totals –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –ø—ã—Ç–∞–µ–º—Å—è –≤—ã—á–∏—Å–ª–∏—Ç—å –∏–∑ months
                        months = quarter_data.get("months", [])
                        if months:
                            active_kwh_total = 0.0
                            reactive_kvarh_total = 0.0
                            for month in months:
                                values = month.get("values", {})
                                if "active_kwh" in values and values["active_kwh"]:
                                    try:
                                        active_kwh_total += float(values["active_kwh"])
                                    except (ValueError, TypeError):
                                        pass
                                if (
                                    "reactive_kvarh" in values
                                    and values["reactive_kvarh"]
                                ):
                                    try:
                                        reactive_kvarh_total += float(
                                            values["reactive_kvarh"]
                                        )
                                    except (ValueError, TypeError):
                                        pass

                            if active_kwh_total > 0:
                                active_kwh_by_quarter[quarter] = active_kwh_total
                            if reactive_kvarh_total > 0:
                                reactive_kvarh_by_quarter[quarter] = (
                                    reactive_kvarh_total
                                )

                            # –°–æ–∑–¥–∞—ë–º quarter_totals –µ—Å–ª–∏ –æ–Ω–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç
                            if active_kwh_total > 0 or reactive_kvarh_total > 0:
                                quarter_totals_by_quarter[quarter] = {
                                    "active_kwh": active_kwh_total
                                    if active_kwh_total > 0
                                    else None,
                                    "reactive_kvarh": reactive_kvarh_total
                                    if reactive_kvarh_total > 0
                                    else None,
                                }

            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            if active_kwh_by_quarter:
                result.setdefault("electricity", {})["active_kwh"] = (
                    active_kwh_by_quarter
                )
            if reactive_kvarh_by_quarter:
                result.setdefault("electricity", {})["reactive_kvarh"] = (
                    reactive_kvarh_by_quarter
                )
            if quarter_totals_by_quarter:
                result.setdefault("electricity", {})["quarter_totals"] = (
                    quarter_totals_by_quarter
                )

        # –ò–∑–≤–ª–µ–∫–∞–µ–º gas –¥–∞–Ω–Ω—ã–µ
        gas_data = resources.get("gas", {})
        logger.debug(
            f"–î–ª—è –ª–∏—Å—Ç–∞ '{sheet_name}': gas_data keys: {list(gas_data.keys()) if gas_data else 'None'}"
        )
        if gas_data:
            volume_m3_by_quarter = {}
            quarter_totals_by_quarter = {}

            for quarter, quarter_data in gas_data.items():
                if isinstance(quarter_data, dict):
                    quarter_totals = quarter_data.get("quarter_totals", {})
                    if quarter_totals:
                        if "volume_m3" in quarter_totals:
                            volume_m3_by_quarter[quarter] = quarter_totals["volume_m3"]
                        quarter_totals_by_quarter[quarter] = quarter_totals
                    else:
                        # –ï—Å–ª–∏ quarter_totals –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –ø—ã—Ç–∞–µ–º—Å—è –≤—ã—á–∏—Å–ª–∏—Ç—å –∏–∑ months
                        months = quarter_data.get("months", [])
                        if months:
                            volume_m3_total = 0.0
                            cost_sum_total = 0.0
                            for month in months:
                                values = month.get("values", {})
                                if "volume_m3" in values and values["volume_m3"]:
                                    try:
                                        volume_m3_total += float(values["volume_m3"])
                                    except (ValueError, TypeError):
                                        pass
                                if "cost_sum" in values and values["cost_sum"]:
                                    try:
                                        cost_sum_total += float(values["cost_sum"])
                                    except (ValueError, TypeError):
                                        pass

                            if volume_m3_total > 0:
                                volume_m3_by_quarter[quarter] = volume_m3_total
                            if volume_m3_total > 0 or cost_sum_total > 0:
                                # –°–æ–∑–¥–∞—ë–º quarter_totals –µ—Å–ª–∏ –æ–Ω–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç
                                quarter_totals_by_quarter[quarter] = {
                                    "volume_m3": volume_m3_total
                                    if volume_m3_total > 0
                                    else None,
                                    "cost_sum": cost_sum_total
                                    if cost_sum_total > 0
                                    else None,
                                }

            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            if volume_m3_by_quarter:
                result.setdefault("gas", {})["volume_m3"] = volume_m3_by_quarter
            if quarter_totals_by_quarter:
                result.setdefault("gas", {})["quarter_totals"] = (
                    quarter_totals_by_quarter
                )

    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ª–∏—Å—Ç–æ–≤
    if "Equipment" in sheet_name or "–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ" in sheet_name:
        result["equipment"] = validation_data.get("equipment", {})

    # –õ–∏—Å—Ç —Ä–∞—Å—á–µ—Ç–∞ —Ç–µ–ø–ª–æ–ø–æ—Ç–µ—Ä—å –ø–æ –∑–¥–∞–Ω–∏—è–º
    if (
        "02_–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ" in sheet_name
        or "–û–≥—Ä–∞–∂–¥–∞—é—â–∏–µ" in sheet_name
        or "Envelope" in sheet_name
    ):
        envelope_data = validation_data.get("envelope", {})
        result["envelope"] = envelope_data
        # –ï—Å–ª–∏ envelope_data —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á "sections", –∏–∑–≤–ª–µ–∫–∞–µ–º items –∏–∑ –∫–∞–∂–¥–æ–π —Å–µ–∫—Ü–∏–∏
        if isinstance(envelope_data, dict) and "sections" in envelope_data:
            sections = envelope_data.get("sections", [])
            all_items = []
            for section in sections:
                if isinstance(section, dict) and "items" in section:
                    all_items.extend(section.get("items", []))
            if all_items:
                result.setdefault("envelope", {})["items"] = all_items

    if "–£–∑–ª—ã" in sheet_name or "Nodes" in sheet_name:
        # nodes_data –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–Ω—ã–º –æ–±—ä–µ–∫—Ç–æ–º —Å –∫–ª—é—á–∞–º–∏ "nodes", "tables", "summary"
        # –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Å–ø–∏—Å–∫–æ–º —É–∑–ª–æ–≤
        nodes_data = validation_data.get("nodes", {})
        if isinstance(nodes_data, dict) and "nodes" in nodes_data:
            # –ï—Å–ª–∏ —ç—Ç–æ –ø–æ–ª–Ω—ã–π –æ–±—ä–µ–∫—Ç, –∏–∑–≤–ª–µ–∫–∞–µ–º —Å–ø–∏—Å–æ–∫ —É–∑–ª–æ–≤
            result["nodes"] = nodes_data.get("nodes", [])
        elif isinstance(nodes_data, list):
            # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ —Å–ø–∏—Å–æ–∫ —É–∑–ª–æ–≤
            result["nodes"] = nodes_data
        else:
            # Fallback: –ø–µ—Ä–µ–¥–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
            result["nodes"] = nodes_data

    if "–ë–∞–ª–∞–Ω—Å" in sheet_name or "Balans" in sheet_name:
        result["usage"] = validation_data.get("usage", {})
        # –î–æ–±–∞–≤–ª—è–µ–º by_usage –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–µ—Å—É—Ä—Å–æ–≤
        electricity_data = resources.get("electricity", {})
        by_usage_aggregated = {}
        quarters_with_by_usage = []
        quarters_without_by_usage = []

        for quarter, quarter_data in electricity_data.items():
            if quarter == "ANNUAL":
                continue
            if isinstance(quarter_data, dict):
                by_usage = quarter_data.get("by_usage")
                if by_usage and isinstance(by_usage, dict) and len(by_usage) > 0:
                    by_usage_aggregated[quarter] = by_usage
                    quarters_with_by_usage.append(quarter)
                else:
                    quarters_without_by_usage.append(quarter)

        if by_usage_aggregated:
            result.setdefault("electricity", {})["by_usage"] = by_usage_aggregated
            logger.info(
                f"‚úÖ –î–ª—è –ª–∏—Å—Ç–∞ '{sheet_name}': by_usage –Ω–∞–π–¥–µ–Ω –≤ {len(by_usage_aggregated)} –∫–≤–∞—Ä—Ç–∞–ª–∞—Ö: {list(by_usage_aggregated.keys())}"
            )
        else:
            logger.warning(
                f"‚ö†Ô∏è –î–ª—è –ª–∏—Å—Ç–∞ '{sheet_name}': by_usage –ù–ï –Ω–∞–π–¥–µ–Ω –Ω–∏ –≤ –æ–¥–Ω–æ–º –∫–≤–∞—Ä—Ç–∞–ª–µ!"
            )
            logger.warning(f"   –ö–≤–∞—Ä—Ç–∞–ª—ã –±–µ–∑ by_usage: {quarters_without_by_usage}")
            logger.warning(f"   –í—Å–µ–≥–æ –∫–≤–∞—Ä—Ç–∞–ª–æ–≤ electricity: {len(electricity_data)}")
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–µ—Ä–≤–æ–≥–æ –∫–≤–∞—Ä—Ç–∞–ª–∞ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
            if electricity_data:
                first_quarter = next(
                    iter([k for k in electricity_data.keys() if k != "ANNUAL"]), None
                )
                if first_quarter:
                    first_data = electricity_data[first_quarter]
                    logger.debug(
                        f"   –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–≤–∞—Ä—Ç–∞–ª–∞ {first_quarter}: {list(first_data.keys()) if isinstance(first_data, dict) else '–Ω–µ —Å–ª–æ–≤–∞—Ä—å'}"
                    )

    return result


def _convert_equipment_json_to_items(equipment_data: Dict[str, Any]) -> List[Any]:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç equipment JSON –≤ —Å–ø–∏—Å–æ–∫ EquipmentItem.

    –°—Ç—Ä—É–∫—Ç—É—Ä–∞ equipment JSON:
    {
        "sheets": [
            {
                "sheet": "Sheet1",
                "sections": [
                    {
                        "title": "1. –¶–µ—Ö ...",
                        "items": [
                            {
                                "name": "–ù–∞—Å–æ—Å",
                                "total_power_kw": 50.0,
                                "unit_power_kw": 25.0,
                                "quantity": 2.0,
                                ...
                            }
                        ]
                    }
                ]
            }
        ]
    }
    """
    from ai.ai_excel_semantic_parser import EquipmentItem

    equipment_items = []

    try:
        sheets = equipment_data.get("sheets", [])
        for sheet in sheets:
            sections = sheet.get("sections", [])
            for section in sections:
                items = section.get("items", [])
                section_title = section.get("title", "")

                for item in items:
                    name = item.get("name", "")
                    if not name:
                        continue

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–æ—â–Ω–æ—Å—Ç—å
                    total_power_kw = item.get("total_power_kw")
                    unit_power_kw = item.get("unit_power_kw")
                    quantity = item.get("quantity", 1.0)

                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º total_power_kw –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –≤—ã—á–∏—Å–ª—è–µ–º –∏–∑ unit_power_kw * quantity
                    nominal_power = total_power_kw
                    if nominal_power is None and unit_power_kw is not None:
                        nominal_power = (
                            float(unit_power_kw) * float(quantity)
                            if quantity
                            else float(unit_power_kw)
                        )

                    if nominal_power is None or nominal_power <= 0:
                        continue

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º location –∏–∑ section title (–Ω–∞–ø—Ä–∏–º–µ—Ä, "1. –¶–µ—Ö ‚Ññ1" -> "–¶–µ—Ö ‚Ññ1")
                    location = None
                    if section_title:
                        # –£–±–∏—Ä–∞–µ–º –Ω–æ–º–µ—Ä —Å–µ–∫—Ü–∏–∏ –∏ —Ç–æ—á–∫—É
                        location = section_title.strip()
                        if location and location[0].isdigit():
                            # –£–±–∏—Ä–∞–µ–º "1. " –∏–ª–∏ "1."
                            parts = location.split(".", 1)
                            if len(parts) > 1:
                                location = parts[1].strip()

                    # –°–æ–∑–¥–∞–µ–º EquipmentItem
                    equipment_item = EquipmentItem(
                        name=str(name),
                        location=location,
                        nominal_power_kw=float(nominal_power),
                        utilization_factor=1.0,  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
                        extra={},
                    )

                    equipment_items.append(equipment_item)

        logger.debug(
            f"–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ {len(equipment_items)} –µ–¥–∏–Ω–∏—Ü –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –∏–∑ JSON"
        )
        return equipment_items

    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ equipment JSON –≤ EquipmentItem: {e}")
        return []
