"""
–ë–∞–∑–æ–≤—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è –º–æ–¥—É–ª—è –∏–º–ø–æ—Ä—Ç–∞ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
"""
import sys
import os
from pathlib import Path
from unittest.mock import Mock, MagicMock, patch
import tempfile
import json

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
INGEST_DIR = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(INGEST_DIR))

import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_file_not_found():
    """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞"""
    print("\n" + "=" * 70)
    print("–¢–ï–°–¢: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
    print("=" * 70)
    
    try:
        from domain.normative_importer import NormativeImporter
        
        importer = NormativeImporter()
        
        # –ü—ã—Ç–∞–µ–º—Å—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
        try:
            result = importer.import_normative_document("/nonexistent/file.pdf")
            print("‚ùå –û–®–ò–ë–ö–ê: –î–æ–ª–∂–Ω–æ –±—ã–ª–æ –±—ã—Ç—å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ FileNotFoundError")
            return False
        except FileNotFoundError as e:
            print(f"‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –æ—à–∏–±–∫–∞: {e}")
            return True
        except Exception as e:
            print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {type(e).__name__}: {e}")
            return False
    except ImportError as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª—å: {e}")
        return False


def test_document_type_detection():
    """–¢–µ—Å—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    print("\n" + "=" * 70)
    print("–¢–ï–°–¢: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
    print("=" * 70)
    
    try:
        from domain.normative_importer import NormativeImporter
        
        importer = NormativeImporter()
        
        test_cases = [
            ("pkm690.pdf", "PKM690"),
            ("690_–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ.doc", "PKM690"),
            ("–ì–û–°–¢_31427-2010.pdf", "GOST"),
            ("gost_12345.docx", "GOST"),
            ("–°–ù–∏–ü_23-02-2003.pdf", "SNiP"),
            ("snip_heating.docx", "SNiP"),
            ("–°–∞–Ω–ü–∏–ù_2.1.4.pdf", "SanPiN"),
            ("–ü–£–≠_7.pdf", "PUE"),
            ("–ü–¢–≠–≠–ü_2024.doc", "PTEEP"),
            ("random_document.pdf", "normative"),
        ]
        
        all_passed = True
        for filename, expected_type in test_cases:
            detected = importer._detect_document_type(filename)
            if detected == expected_type:
                print(f"‚úÖ {filename:30} -> {detected}")
            else:
                print(f"‚ùå {filename:30} -> {detected} (–æ–∂–∏–¥–∞–ª–æ—Å—å: {expected_type})")
                all_passed = False
        
        return all_passed
    except ImportError as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª—å: {e}")
        return False


def test_file_hash_calculation():
    """–¢–µ—Å—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ö–µ—à–∞ —Ñ–∞–π–ª–∞"""
    print("\n" + "=" * 70)
    print("–¢–ï–°–¢: –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ö–µ—à–∞ —Ñ–∞–π–ª–∞")
    print("=" * 70)
    
    try:
        from domain.normative_importer import NormativeImporter
        
        importer = NormativeImporter()
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as f:
            test_content = "–¢–µ—Å—Ç–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ö–µ—à–∞"
            f.write(test_content)
            temp_path = f.name
        
        try:
            # –í—ã—á–∏—Å–ª—è–µ–º —Ö–µ—à
            file_hash = importer._calculate_file_hash(temp_path)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ö–µ—à - —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞ –∏–∑ 40 —Å–∏–º–≤–æ–ª–æ–≤ (SHA1)
            if isinstance(file_hash, str) and len(file_hash) == 40:
                print(f"‚úÖ –•–µ—à –≤—ã—á–∏—Å–ª–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ: {file_hash[:20]}...")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ö–µ—à –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                hash2 = importer._calculate_file_hash(temp_path)
                if file_hash == hash2:
                    print("‚úÖ –•–µ—à —Å—Ç–∞–±–∏–ª–µ–Ω (–æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞)")
                    return True
                else:
                    print("‚ùå –•–µ—à –Ω–µ—Å—Ç–∞–±–∏–ª–µ–Ω")
                    return False
            else:
                print(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ö–µ—à–∞: {file_hash}")
                return False
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            os.unlink(temp_path)
    except ImportError as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª—å: {e}")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return False


def test_text_extraction_from_parsed_result():
    """–¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    print("\n" + "=" * 70)
    print("–¢–ï–°–¢: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞")
    print("=" * 70)
    
    try:
        from domain.normative_importer import NormativeImporter
        
        importer = NormativeImporter()
        
        # –¢–µ—Å—Ç 1: PDF —Å —Ç–µ–∫—Å—Ç–æ–º
        pdf_result = {
            "parsing": {
                "data": {
                    "text": "–≠—Ç–æ —Ç–µ–∫—Å—Ç –∏–∑ PDF –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å —Ñ–æ—Ä–º—É–ª–æ–π Q = A * B"
                }
            }
        }
        
        text = importer._extract_text_content(pdf_result)
        if "—Ñ–æ—Ä–º—É–ª–æ–π Q = A * B" in text:
            print("‚úÖ –¢–µ–∫—Å—Ç –∏–∑ PDF –∏–∑–≤–ª–µ—á–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        else:
            print(f"‚ùå –¢–µ–∫—Å—Ç –∏–∑ PDF –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω: {text[:50]}...")
            return False
        
        # –¢–µ—Å—Ç 2: Word —Å –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º–∏
        word_result = {
            "parsing": {
                "data": {
                    "paragraphs": [
                        {"text": "–ü–∞—Ä–∞–≥—Ä–∞—Ñ 1"},
                        {"text": "–ü–∞—Ä–∞–≥—Ä–∞—Ñ 2 —Å –Ω–æ—Ä–º–∞—Ç–∏–≤–æ–º 0.15 –∫–í—Ç¬∑—á/–º¬≤"}
                    ]
                }
            }
        }
        
        text = importer._extract_text_content(word_result)
        if "–Ω–æ—Ä–º–∞—Ç–∏–≤–æ–º 0.15" in text:
            print("‚úÖ –¢–µ–∫—Å—Ç –∏–∑ Word –∏–∑–≤–ª–µ—á–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        else:
            print(f"‚ùå –¢–µ–∫—Å—Ç –∏–∑ Word –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω: {text[:50]}...")
            return False
        
        # –¢–µ—Å—Ç 3: Excel —Å –ª–∏—Å—Ç–∞–º–∏
        excel_result = {
            "parsing": {
                "data": {
                    "sheets": [
                        {
                            "name": "–õ–∏—Å—Ç1",
                            "rows": [
                                ["–ö–æ–ª–æ–Ω–∫–∞1", "–ö–æ–ª–æ–Ω–∫–∞2", "–ó–Ω–∞—á–µ–Ω–∏–µ"],
                                ["–≠–Ω–µ—Ä–≥–∏—è", "–∫–í—Ç¬∑—á", "1000"]
                            ]
                        }
                    ]
                }
            }
        }
        
        text = importer._extract_text_content(excel_result)
        if "–≠–Ω–µ—Ä–≥–∏—è" in text and "1000" in text:
            print("‚úÖ –¢–µ–∫—Å—Ç –∏–∑ Excel –∏–∑–≤–ª–µ—á–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        else:
            print(f"‚ùå –¢–µ–∫—Å—Ç –∏–∑ Excel –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω: {text[:50]}...")
            return False
        
        # –¢–µ—Å—Ç 4: –ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        empty_result = {}
        text = importer._extract_text_content(empty_result)
        if text == "":
            print("‚úÖ –ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        else:
            print(f"‚ùå –ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω –Ω–µ–≤–µ—Ä–Ω–æ: {text}")
            return False
        
        return True
    except ImportError as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª—å: {e}")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_ai_extraction_without_ai():
    """–¢–µ—Å—Ç –ø–æ–≤–µ–¥–µ–Ω–∏—è –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ–º AI"""
    print("\n" + "=" * 70)
    print("–¢–ï–°–¢: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª –±–µ–∑ AI")
    print("=" * 70)
    
    try:
        from domain.normative_importer import NormativeImporter
        
        # –°–æ–∑–¥–∞–µ–º –∏–º–ø–æ—Ä—Ç–µ—Ä —Å –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã–º AI
        importer = NormativeImporter()
        importer.ai_parser = None
        
        parsed_result = {
            "parsing": {
                "data": {
                    "text": "–¢–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç"
                }
            }
        }
        
        rules = importer._extract_rules_with_ai(parsed_result, 1, "PKM690")
        
        if rules == []:
            print("‚úÖ –ë–µ–∑ AI –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∞–≤–∏–ª")
            return True
        else:
            print(f"‚ùå –ë–µ–∑ AI –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø—É—Å—Ç—ã–µ –ø—Ä–∞–≤–∏–ª–∞, –ø–æ–ª—É—á–µ–Ω–æ: {len(rules)}")
            return False
    except ImportError as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª—å: {e}")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_parse_ai_extraction_result():
    """–¢–µ—Å—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ AI"""
    print("\n" + "=" * 70)
    print("–¢–ï–°–¢: –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ AI")
    print("=" * 70)
    
    try:
        from domain.normative_importer import NormativeImporter
        
        importer = NormativeImporter()
        
        # –¢–µ—Å—Ç 1: –ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON –æ—Ç–≤–µ—Ç
        ai_response = """
        {
            "rules": [
                {
                    "rule_type": "formula",
                    "description": "–†–∞—Å—á–µ—Ç —Ç–µ–ø–ª–æ–ø–æ—Ç–µ—Ä—å",
                    "formula": "Q = A * ŒîT / R",
                    "parameters": {"A": "–ø–ª–æ—â–∞–¥—å, –º¬≤", "ŒîT": "—Ä–∞–∑–Ω–∏—Ü–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä, ¬∞C"},
                    "numeric_value": null,
                    "unit": "–∫–í—Ç¬∑—á",
                    "confidence": 0.9,
                    "references": []
                }
            ]
        }
        """
        
        rules = importer._parse_ai_extraction_result(ai_response, "PKM690")
        
        if len(rules) == 1 and rules[0]["rule_type"] == "formula":
            print("‚úÖ –ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON –æ—Ç–≤–µ—Ç —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω")
        else:
            print(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥: {rules}")
            return False
        
        # –¢–µ—Å—Ç 2: JSON –≤ markdown –±–ª–æ–∫–µ
        ai_response_markdown = """
        –í–æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç:
        ```json
        {
            "rules": [
                {
                    "rule_type": "normative",
                    "description": "–ù–æ—Ä–º–∞—Ç–∏–≤",
                    "numeric_value": 0.15,
                    "unit": "–∫–í—Ç¬∑—á/–º¬≤",
                    "confidence": 0.8
                }
            ]
        }
        ```
        """
        
        rules = importer._parse_ai_extraction_result(ai_response_markdown, "PKM690")
        
        if len(rules) == 1 and rules[0]["rule_type"] == "normative":
            print("‚úÖ JSON –≤ markdown –±–ª–æ–∫–µ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω")
        else:
            print(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ markdown: {rules}")
            return False
        
        # –¢–µ—Å—Ç 3: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON
        invalid_json = "–≠—Ç–æ –Ω–µ JSON {–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç}"
        rules = importer._parse_ai_extraction_result(invalid_json, "PKM690")
        
        if rules == []:
            print("‚úÖ –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON –æ–±—Ä–∞–±–æ—Ç–∞–Ω (–ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫)")
        else:
            print(f"‚ùå –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON –¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫: {rules}")
            return False
        
        # –¢–µ—Å—Ç 4: –ü—Ä–∞–≤–∏–ª–æ –±–µ–∑ rule_type
        ai_response_no_type = """
        {
            "rules": [
                {
                    "description": "–ü—Ä–∞–≤–∏–ª–æ –±–µ–∑ —Ç–∏–ø–∞"
                }
            ]
        }
        """
        
        rules = importer._parse_ai_extraction_result(ai_response_no_type, "PKM690")
        
        if len(rules) == 1 and rules[0]["rule_type"] == "unknown":
            print("‚úÖ –ü—Ä–∞–≤–∏–ª–æ –±–µ–∑ —Ç–∏–ø–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ (–¥–æ–±–∞–≤–ª–µ–Ω 'unknown')")
        else:
            print(f"‚ùå –ü—Ä–∞–≤–∏–ª–æ –±–µ–∑ —Ç–∏–ø–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –Ω–µ–≤–µ—Ä–Ω–æ: {rules}")
            return False
        
        return True
    except ImportError as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª—å: {e}")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_all_tests():
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ —Ç–µ—Å—Ç—ã"""
    print("\n" + "=" * 70)
    print("–ó–ê–ü–£–°–ö –ë–ê–ó–û–í–´–• –¢–ï–°–¢–û–í –î–õ–Ø –ú–û–î–£–õ–Ø –ò–ú–ü–û–†–¢–ê –ù–û–†–ú–ê–¢–ò–í–û–í")
    print("=" * 70)
    
    tests = [
        ("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω", test_file_not_found),
        ("–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞", test_document_type_detection),
        ("–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ö–µ—à–∞ —Ñ–∞–π–ª–∞", test_file_hash_calculation),
        ("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞", test_text_extraction_from_parsed_result),
        ("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–µ–∑ AI", test_ai_extraction_without_ai),
        ("–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ AI", test_parse_ai_extraction_result),
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"\n‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –≤ —Ç–µ—Å—Ç–µ '{test_name}': {e}")
            import traceback
            traceback.print_exc()
            results.append((test_name, False))
    
    # –ò—Ç–æ–≥–∏
    print("\n" + "=" * 70)
    print("–ò–¢–û–ì–ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
    print("=" * 70)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "‚úÖ –ü–†–û–ô–î–ï–ù" if result else "‚ùå –ü–†–û–í–ê–õ–ï–ù"
        print(f"{status:15} - {test_name}")
    
    print(f"\n–í—Å–µ–≥–æ: {passed}/{total} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ")
    
    if passed == total:
        print("\nüéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        return True
    else:
        print(f"\n‚ö†Ô∏è {total - passed} —Ç–µ—Å—Ç(–æ–≤) –ø—Ä–æ–≤–∞–ª–µ–Ω–æ")
        return False


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)

