"""
–¢–µ—Å—Ç—ã –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
"""
import sys
import os
import tempfile
from pathlib import Path
from unittest.mock import patch, MagicMock

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
INGEST_DIR = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(INGEST_DIR))

import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_deduplication_by_hash():
    """–¢–µ—Å—Ç –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –ø–æ —Ö–µ—à—É —Ñ–∞–π–ª–∞"""
    print("\n" + "=" * 70)
    print("–¢–ï–°–¢: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print("=" * 70)
    
    try:
        from domain.normative_importer import NormativeImporter
        import database
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ë–î
        database.init_db()
        
        importer = NormativeImporter()
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as f:
            test_content = "–¢–µ—Å—Ç–æ–≤—ã–π –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏"
            f.write(test_content)
            temp_path = f.name
        
        try:
            # –ü–µ—Ä–≤—ã–π –∏–º–ø–æ—Ä—Ç (–º–æ–∫–∞–µ–º AI –∏ –ø–∞—Ä—Å–∏–Ω–≥)
            with patch.object(importer, '_parse_document') as mock_parse, \
                 patch.object(importer, '_extract_rules_with_ai') as mock_ai:
                
                mock_parse.return_value = {
                    "parsing": {
                        "data": {
                            "text": test_content
                        }
                    }
                }
                mock_ai.return_value = [
                    {
                        "rule_type": "normative",
                        "description": "–¢–µ—Å—Ç–æ–≤—ã–π –Ω–æ—Ä–º–∞—Ç–∏–≤",
                        "numeric_value": 0.15,
                        "unit": "–∫–í—Ç¬∑—á/–º¬≤",
                        "confidence": 0.9,
                        "references": []
                    }
                ]
                
                # –ü–µ—Ä–≤—ã–π –∏–º–ø–æ—Ä—Ç
                result1 = importer.import_normative_document(
                    temp_path,
                    title="–¢–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç 1",
                    document_type="PKM690"
                )
                
                if result1.get("status") == "processed":
                    doc_id_1 = result1["document_id"]
                    print(f"‚úÖ –ü–µ—Ä–≤—ã–π –∏–º–ø–æ—Ä—Ç —É—Å–ø–µ—à–µ–Ω: ID={doc_id_1}")
                else:
                    print(f"‚ùå –ü–µ—Ä–≤—ã–π –∏–º–ø–æ—Ä—Ç –Ω–µ —É–¥–∞–ª—Å—è: {result1}")
                    return False
                
                # –í—Ç–æ—Ä–æ–π –∏–º–ø–æ—Ä—Ç —Ç–æ–≥–æ –∂–µ —Ñ–∞–π–ª–∞ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥—É–±–ª–∏–∫–∞—Ç)
                result2 = importer.import_normative_document(
                    temp_path,
                    title="–¢–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç 2",  # –î—Ä—É–≥–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ, –Ω–æ —Ç–æ—Ç –∂–µ —Ñ–∞–π–ª
                    document_type="PKM690"
                )
                
                if result2.get("status") == "duplicate":
                    if result2["document_id"] == doc_id_1:
                        print(f"‚úÖ –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç: –æ–±–Ω–∞—Ä—É–∂–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç ID={doc_id_1}")
                        print(f"   –°–æ–æ–±—â–µ–Ω–∏–µ: {result2.get('message')}")
                        return True
                    else:
                        print(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π ID –¥—É–±–ª–∏–∫–∞—Ç–∞: {result2['document_id']} != {doc_id_1}")
                        return False
                else:
                    print(f"‚ùå –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞: —Å—Ç–∞—Ç—É—Å={result2.get('status')}")
                    print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {result2}")
                    return False
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if os.path.exists(temp_path):
                os.unlink(temp_path)
    except ImportError as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª—å: {e}")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_full_text_saving():
    """–¢–µ—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤ –ë–î"""
    print("\n" + "=" * 70)
    print("–¢–ï–°–¢: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
    print("=" * 70)
    
    try:
        from domain.normative_importer import NormativeImporter
        import database
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ë–î
        database.init_db()
        
        importer = NormativeImporter()
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º
        test_text = "–≠—Ç–æ –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞. –§–æ—Ä–º—É–ª–∞: Q = A * B. –ù–æ—Ä–º–∞—Ç–∏–≤: 0.15 –∫–í—Ç¬∑—á/–º¬≤"
        
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as f:
            f.write(test_text)
            temp_path = f.name
        
        try:
            # –ò–º–ø–æ—Ä—Ç —Å –º–æ–∫–∞–º–∏
            with patch.object(importer, '_parse_document') as mock_parse, \
                 patch.object(importer, '_extract_rules_with_ai') as mock_ai:
                
                mock_parse.return_value = {
                    "parsing": {
                        "data": {
                            "text": test_text
                        }
                    }
                }
                mock_ai.return_value = []
                
                result = importer.import_normative_document(
                    temp_path,
                    title="–¢–µ—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞",
                    document_type="PKM690"
                )
                
                if result.get("status") == "processed":
                    doc_id = result["document_id"]
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω
                    doc = database.get_normative_document(doc_id)
                    
                    if doc and doc.get("full_text"):
                        saved_text = doc["full_text"]
                        if test_text in saved_text or saved_text == test_text:
                            print(f"‚úÖ –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –ë–î (ID={doc_id})")
                            print(f"   –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(saved_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º parsed_data_json
                            if doc.get("parsed_data_json"):
                                print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
                                return True
                            else:
                                print("‚ö†Ô∏è –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
                                return True  # –ù–µ –∫—Ä–∏—Ç–∏—á–Ω–æ
                        else:
                            print(f"‚ùå –¢–µ–∫—Å—Ç –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ '{saved_text[:50]}...', –æ–∂–∏–¥–∞–ª–æ—Å—å '{test_text[:50]}...'")
                            return False
                    else:
                        print(f"‚ùå –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –ë–î")
                        return False
                else:
                    print(f"‚ùå –ò–º–ø–æ—Ä—Ç –Ω–µ —É–¥–∞–ª—Å—è: {result}")
                    return False
        finally:
            if os.path.exists(temp_path):
                os.unlink(temp_path)
    except ImportError as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª—å: {e}")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_get_document_text():
    """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –ë–î"""
    print("\n" + "=" * 70)
    print("–¢–ï–°–¢: –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –ë–î")
    print("=" * 70)
    
    try:
        import database
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ë–î
        database.init_db()
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞–ø—Ä—è–º—É—é –≤ –ë–î
        test_text = "–¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–∑ –ë–î"
        doc = database.create_normative_document(
            title="–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞",
            document_type="PKM690",
            file_path="/test/path.pdf",
            file_hash="test_hash_123",
            file_size=1000,
            full_text=test_text,
            parsed_data_json='{"test": "data"}'
        )
        
        doc_id = doc["id"]
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
        retrieved_doc = database.get_normative_document(doc_id)
        
        if retrieved_doc:
            if retrieved_doc.get("full_text") == test_text:
                print(f"‚úÖ –¢–µ–∫—Å—Ç —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –∏–∑ –ë–î (ID={doc_id})")
                return True
            else:
                print(f"‚ùå –¢–µ–∫—Å—Ç –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç")
                return False
        else:
            print(f"‚ùå –î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False
    except ImportError as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª—å: {e}")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_all_tests():
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ —Ç–µ—Å—Ç—ã –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏"""
    print("\n" + "=" * 70)
    print("–ó–ê–ü–£–°–ö –¢–ï–°–¢–û–í –î–ï–î–£–ü–õ–ò–ö–ê–¶–ò–ò –ò –°–û–•–†–ê–ù–ï–ù–ò–Ø –¢–ï–ö–°–¢–ê")
    print("=" * 70)
    
    tests = [
        ("–î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ —Ö–µ—à—É", test_deduplication_by_hash),
        ("–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞", test_full_text_saving),
        ("–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –ë–î", test_get_document_text),
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"\n‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –≤ —Ç–µ—Å—Ç–µ '{test_name}': {e}")
            import traceback
            traceback.print_exc()
            results.append((test_name, False))
    
    # –ò—Ç–æ–≥–∏
    print("\n" + "=" * 70)
    print("–ò–¢–û–ì–ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
    print("=" * 70)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "‚úÖ –ü–†–û–ô–î–ï–ù" if result else "‚ùå –ü–†–û–í–ê–õ–ï–ù"
        print(f"{status:15} - {test_name}")
    
    print(f"\n–í—Å–µ–≥–æ: {passed}/{total} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ")
    
    if passed == total:
        print("\nüéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        return True
    else:
        print(f"\n‚ö†Ô∏è {total - passed} —Ç–µ—Å—Ç(–æ–≤) –ø—Ä–æ–≤–∞–ª–µ–Ω–æ")
        return False


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)

